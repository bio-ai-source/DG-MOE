import itertools
import json
import numpy as np
import torch
import time
from torch.nn import CrossEntropyLoss
from tqdm import tqdm
from utils import set_seed, get_dataloader, Lookahead, get_kfold_data
from dataset import load_dataset
from train import train, valid, test
from torch.optim import Optimizer, SGD
from torch.utils.data import random_split
from hyperparameter import hyperparameter
from model.model import DTI
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
hp = hyperparameter()
hp.current_time = time.time()
type = hp.type
DATASET = hp.DATASET
set_seed(hp.seed_cross)
device = hp.device

if hp.DATASET == 'DrugBank':
    weight_CE = None
elif hp.DATASET == 'Davis':
    weight_CE = torch.FloatTensor([0.3, 0.7]).cuda()
else:
    weight_CE = None

dataset, molecule_graph, protein_graph, molecule_embedding, protein_embedding, gene_embedding = load_dataset(dataname=DATASET)
config = {
            # MLP
            'layer_output': hp.mlp_layer_output,
            # GAT
            'num_layers': hp.num_layers,
            'num_heads': hp.num_heads,
            'dropout': hp.dropout,
            'drug_in_channels': 1024,
            'drug_out_channels': 1024,
            'protein_in_channels': 1280,
            'protein_out_channels': 1280,
            'p_cum': -2.25
        }

Epoch_List_test, Accuracy_List_test, Precision_List_test, Recall_List_test, F1_List_test, AUC_List_test, AUPR_List_test = [], [], [], [], [], [], []
best_test_labels, best_test_scores, best_drug_ids, best_protein_ids = [], [], [], []
best_fold_results = []
all_test_labels, all_test_scores = [], []


for i_fold in range(hp.K_Fold):
    train_dataset, test_dataset = get_kfold_data(i_fold, dataset, hp.K_Fold)
    train_size = len(train_dataset)
    test_size = len(test_dataset)
    valid_size = int(train_size * 0.2)
    train_size = train_size - valid_size
    train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])
    print(f"Train dataset size: {train_size}")
    print(f"Valid dataset size: {valid_size}")
    print(f"Test dataset size: {test_size}")
    train_drug_loader, train_protein_loader, valid_drug_loader, valid_protein_loader, test_drug_loader, test_protein_loader = get_dataloader(
        train_dataset, valid_dataset, test_dataset, molecule_graph, protein_graph, molecule_embedding,
        protein_embedding, gene_embedding, batch=hp.batch)

    model = DTI(**config).to(device)
    if hp.skip_train == False:
        optimizer_inner = SGD(model.parameters(), lr=hp.Learning_rate, weight_decay=hp.weight_decay)
        optimizer = Lookahead(optimizer_inner, k=0, alpha=0.5)
        criterion = CrossEntropyLoss().to(device)
        best_epoch, es, max_valid_auc = 0, 0, 0
        for epoch in range(hp.epochs):
            train_loss, train_labels, train_scores, train_acc, train_auc, train_aupr, train_precision, train_recall, train_f1, train_MCC = train(
                i_fold, epoch, model, train_drug_loader, train_protein_loader, optimizer, criterion, device)
            valid_loss, valid_labels, valid_scores, valid_acc, valid_auc, valid_aupr, valid_precision, valid_recall, valid_f1, valid_MCC = valid(
                i_fold, epoch, model, valid_drug_loader, valid_protein_loader, criterion, device)
            if max_valid_auc < valid_auc:
                es = 0
                max_valid_auc = valid_auc
                torch.save(model.state_dict(), f"results/{DATASET}/{type}/fold_{i_fold}/model.pth")  # 保存预测模型
            else:
                es += 1
            if es == 5:
                Epoch_List_test.append(epoch)
                break
            print('*' * 25 + ' End Metrics ' + '*' * 25)
            print(f"Epoch： {epoch} Train: Loss={train_loss:.8f}, Acc={train_acc:.4f}, AUC={train_auc:.4f}, AUPR={train_aupr:.4f}, Precision={train_precision:.4f}, Recall={train_recall:.4f}, F1={train_f1:.4f}, MCC={train_MCC:.4f}")
            print(f"Epoch： {epoch} Valid: Loss={valid_loss:.8f}, Acc={valid_acc:.4f}, AUC={valid_auc:.4f}, AUPR={valid_aupr:.4f}, Precision={valid_precision:.4f}, Recall={valid_recall:.4f}, F1={valid_f1:.4f}, MCC={valid_MCC:.4f}")

    model.load_state_dict(torch.load(f"results/{DATASET}/{type}/fold_{i_fold}/model.pth")) #加载模型
    df, predict_result, test_labels, test_scores, fpr, tpr, test_acc, test_auc, test_aupr, test_precision, test_recall, test_f1, test_MCC = test(
        i_fold, model, test_drug_loader, test_protein_loader, device)

    print(
        f"Test:  Acc={test_acc:.4f}, AUC={test_auc:.4f}, AUPR={test_aupr:.4f}, Precision={test_precision:.4f}, Recall={test_recall:.4f}, F1={test_f1:.4f}, MCC={test_MCC:.4f}")
all_test_labels.extend(test_labels)
all_test_scores.extend(test_scores)
Accuracy_List_test.append(test_acc)
Precision_List_test.append(test_precision)
Recall_List_test.append(test_recall)
F1_List_test.append(test_f1)
AUC_List_test.append(test_auc)
AUPR_List_test.append(test_aupr)
# Calculate mean and std
metrics = {
    "Accuracy": Accuracy_List_test,
    "Precision": Precision_List_test,
    "Recall": Recall_List_test,
    "F1": F1_List_test,
    "AUC": AUC_List_test,
    "AUPR": AUPR_List_test
}

# Compute means and stds
mean_std = {metric: {"mean": np.mean(values), "std": np.std(values)} for metric, values in metrics.items()}
print(mean_std)